{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/staerkjoe/NLP_colab/blob/main/AML4NLP2025_E04_Intro_W%26B_Weave.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2b1e4b4429198fae"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction: Eploring Weights & Biases Weave\n",
        "\n",
        "ITU KSAMLDS1KU - Advanced Machine Learning for Data Science 2025\n",
        "\n",
        "by Jonathan Tiedchen, Eisuke Okuda, Stefan Heinrich,\n",
        "& material by Bertram HÃ¸jer, Kevin Murphy, and Chris Bishop.\n",
        "\n",
        "All info and static material: https://learnit.itu.dk/course/view.php?id=3024752\n",
        "\n",
        "-------------------------------------------------------------------------------"
      ],
      "id": "2b1e4b4429198fae"
    },
    {
      "metadata": {
        "id": "4b4a2ce0d3937577"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Install dependencies"
      ],
      "id": "4b4a2ce0d3937577"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc05691c",
      "metadata": {
        "id": "dc05691c"
      },
      "outputs": [],
      "source": [
        "!pip install wandb weave transformers datasets torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b58524a",
      "metadata": {
        "id": "9b58524a"
      },
      "source": [
        "### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307d2492",
      "metadata": {
        "id": "307d2492"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import weave\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee1e7ae",
      "metadata": {
        "id": "fee1e7ae"
      },
      "source": [
        "### 3. Initialize W&B and Weave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f9cc6a",
      "metadata": {
        "id": "d2f9cc6a",
        "outputId": "f1499503-0a9d-4649-bbb1-1d1622c067e0",
        "colab": {
          "referenced_widgets": [
            "905f44fccb244ae2a98821522750cac4",
            "4c8ea095228c4227ae701cfc0949d3aa"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-paper-1</strong> at: <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/92gfwedt' target=\"_blank\">https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/92gfwedt</a><br> View project at: <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging' target=\"_blank\">https://wandb.ai/jonathantied-private/llm_prompt_logging</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250904_224207-92gfwedt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:\n",
            "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
            "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for wandb.init()..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:\n",
            "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
            "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/ITU/AML4NLP2025-teaching/W04-regularisation-hyperoptimisation/wandb/run-20250904_224422-y6lxdl7b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/y6lxdl7b' target=\"_blank\">efficient-deluge-2</a></strong> to <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging' target=\"_blank\">https://wandb.ai/jonathantied-private/llm_prompt_logging</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/y6lxdl7b' target=\"_blank\">https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/y6lxdl7b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Initializing weave.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "905f44fccb244ae2a98821522750cac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: jonathantied.\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/jonathantied-private/llm_prompt_logging/weave\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c8ea095228c4227ae701cfc0949d3aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: jonathantied.\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/jonathantied-private/llm_prompt_logging/weave\n"
          ]
        }
      ],
      "source": [
        "# Login to W&B\n",
        "wandb.login()\n",
        "\n",
        "# Start a new run\n",
        "wandb_run = wandb.init(\n",
        "    project=\"llm_prompt_logging\",\n",
        "    config={\n",
        "        \"model\": \"sshleifer/tiny-gpt2\",\n",
        "        \"max_new_tokens\": 50,\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        ")\n",
        "\n",
        "# Initialize Weave client\n",
        "client = weave.init(\"jonathantied-private/llm_prompt_logging\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96dcd64e",
      "metadata": {
        "id": "96dcd64e"
      },
      "source": [
        "### 4. Load a Small Model (tiny GPT-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be82258b",
      "metadata": {
        "id": "be82258b",
        "outputId": "8393a006-37a7-427c-bfd0-dd156bac2024",
        "colab": {
          "referenced_widgets": [
            "9099f13fe34944db9a8652ed685d4b7f",
            "4c8c309d10d5463a94c8f130d27e946a",
            "fa0faed69ee44f37955978a37d7b6af7",
            "62c5a41b981f475cabde834f92eef39b",
            "5265ea1a71ba46fc9af07b8619ab3267",
            "23862da1be454d4a90cd32af3be84202"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9099f13fe34944db9a8652ed685d4b7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c8c309d10d5463a94c8f130d27e946a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa0faed69ee44f37955978a37d7b6af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62c5a41b981f475cabde834f92eef39b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5265ea1a71ba46fc9af07b8619ab3267",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23862da1be454d4a90cd32af3be84202",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.51M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "model_name = wandb.config[\"model\"]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810ad938",
      "metadata": {
        "id": "810ad938"
      },
      "source": [
        "### 5. Define a Prompt Function with Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ff1a9c",
      "metadata": {
        "id": "98ff1a9c"
      },
      "outputs": [],
      "source": [
        "def prompt_model(question, temperature=0.7, max_new_tokens=50):\n",
        "    # Create Weave call\n",
        "    call = client.create_call(\n",
        "        op=\"prompt_model\",\n",
        "        inputs={\n",
        "            \"question\": question,\n",
        "            \"temperature\": temperature,\n",
        "            \"max_new_tokens\": max_new_tokens\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Encode input\n",
        "    input_text = f\"Q: {question}\\nA:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    answer = output_text.split(\"A:\")[-1].strip()\n",
        "\n",
        "    # Log to W&B\n",
        "    wandb.log({\"question\": question, \"answer\": answer})\n",
        "\n",
        "    # Finish Weave call\n",
        "    client.finish_call(call, output={\"answer\": answer})\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6deca7f3",
      "metadata": {
        "id": "6deca7f3"
      },
      "source": [
        "### 6. Run a few examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e93a1a",
      "metadata": {
        "id": "01e93a1a",
        "outputId": "49abf3cc-8324-48ab-d677-7ee6806ec683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: What is 2+2?\n",
            "A: stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs\n",
            "\n",
            "Q: Explain the capital of France.\n",
            "A: stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs\n",
            "\n",
            "Q: Who wrote the book 1984?\n",
            "A: stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs stairs\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/jonathantied-private/llm_prompt_logging/r/call/01991679-7442-7ff6-94f7-6aa4e959111e\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/jonathantied-private/llm_prompt_logging/r/call/01991679-72a7-7a91-ba53-2296eebe4bca\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/jonathantied-private/llm_prompt_logging/r/call/01991679-7421-796e-aa5f-3d86736111c6\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    \"What is 2+2?\",\n",
        "    \"Explain the capital of France.\",\n",
        "    \"Who wrote the book 1984?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    ans = prompt_model(q, temperature=wandb.config[\"temperature\"])\n",
        "    print(f\"Q: {q}\\nA: {ans}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "021b14d6",
      "metadata": {
        "id": "021b14d6"
      },
      "source": [
        "### 7. Finish Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22202b64",
      "metadata": {
        "id": "22202b64",
        "outputId": "00bbc0b8-fabe-4653-c13f-bc7e6c856857"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer</td><td>stairs stairs stairs...</td></tr><tr><td>question</td><td>Who wrote the book 1...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">efficient-deluge-2</strong> at: <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/y6lxdl7b' target=\"_blank\">https://wandb.ai/jonathantied-private/llm_prompt_logging/runs/y6lxdl7b</a><br> View project at: <a href='https://wandb.ai/jonathantied-private/llm_prompt_logging' target=\"_blank\">https://wandb.ai/jonathantied-private/llm_prompt_logging</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250904_224422-y6lxdl7b/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}